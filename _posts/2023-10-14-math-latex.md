---
title: Summary
author: Tao He
date: 2023-10-14
category: Jekyll
layout: post
mermaid: true
---



> ##### Summary
>
> In this website, we have explored the entire process of self-learning large language models (LLMs), from pre-training to reinforcement learning. Here’s a summary of what we’ve learned:
{: .block-tip }

## 1. Pre-Training Stage

Pre-training is the foundational stage of large language models. By learning from a vast amount of data, the model masters the basic structure and patterns of language. This stage includes several important steps:

- **Data Download and Pre-Processing:** We start by collecting and processing a large corpus of text data to prepare for subsequent training.
  
- **Tokenization:** The text is then tokenized to convert it into an input format that the model can understand.
  
- **Neural Network Training:** Through training the neural network, the model learns language patterns and regularities present in the text data.
  
- **Inference:** Once training is complete, the model can perform inference and generate output based on input text.

Additionally, this stage includes exploring and understanding foundational models such as GPT-2, which serve as a starting point for building more powerful models.

## 2. Post-Training

### 2.1 Supervised Fine-Tuning

The fine-tuning stage is crucial for optimizing the model further. In this phase, the pre-trained model is adjusted according to the specific task requirements, allowing it to better adapt to tasks such as text generation and question answering by training on labeled datasets.

### 2.2 Reinforcement Learning

Reinforcement learning plays a vital role in LLM development, especially in dynamic environments and complex problem-solving. We introduced the basic concepts of reinforcement learning and how it enhances the model's performance and adaptability.

### 2.3 Reinforcement Learning with Human Feedback (RLHF)

In this process, the model benefits not only from algorithmic feedback but also from human feedback. By integrating reinforcement learning with human insights, the model gradually learns to provide more reasonable and accurate responses in practical applications.

Through this overview, you should now have a solid understanding of the two key steps in LLM development: pre-training and post-training. To conclude your learning journey, let’s take a small test!
